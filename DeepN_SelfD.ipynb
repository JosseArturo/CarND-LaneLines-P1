{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepN-SelfD.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JosseArturo/CarND-LaneLines-P1/blob/master/DeepN_SelfD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6ewKhLfBPzmE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Simple Net with Relu in the hiddenLayer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1mSoDtjvP-mO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initiate the weights\n",
        "import tensorflow as tf\n",
        "\n",
        "output = None\n",
        "hidden_layer_weights = [\n",
        "    [0.1, 0.2, 0.4],\n",
        "    [0.4, 0.6, 0.6],\n",
        "    [0.5, 0.9, 0.1],\n",
        "    [0.8, 0.2, 0.8]]\n",
        "out_weights = [\n",
        "    [0.1, 0.6],\n",
        "    [0.2, 0.1],\n",
        "    [0.7, 0.9]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C-WK0Gr9QD8k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Weights and biases\n",
        "weights = [\n",
        "    tf.Variable(hidden_layer_weights),\n",
        "    tf.Variable(out_weights)]\n",
        "biases = [\n",
        "    tf.Variable(tf.zeros(3)),\n",
        "    tf.Variable(tf.zeros(2))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6CbrSbsPQLB7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Input\n",
        "features = tf.Variable([[1.0, 2.0, 3.0, 4.0], [-1.0, -2.0, -3.0, -4.0], [11.0, 12.0, 13.0, 14.0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2OFUqKVyQNcb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Create Model\n",
        "hidden_layer = tf.add(tf.matmul(features, weights[0]), biases[0])\n",
        "hidden_layer = tf.nn.relu(hidden_layer)\n",
        "logits = tf.add(tf.matmul(hidden_layer, weights[1]), biases[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "njslIIUOQQCT",
        "colab_type": "code",
        "outputId": "14b0bacd-1d86-4d1f-f226-82f46d1e0c53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# TODO: save and print session results on a variable named \"output\"\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    output = sess.run(logits)\n",
        "    print(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 5.11      8.440001]\n",
            " [ 0.        0.      ]\n",
            " [24.01     38.24    ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l0O-m1IcU3Aj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Simple deep neural network with TF"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OgcOWW3DU6kV",
        "colab_type": "code",
        "outputId": "68097460-bf28-4acd-fc4e-0f8752c2e658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./train-images-idx3-ubyte.gz\n",
            "Extracting ./train-labels-idx1-ubyte.gz\n",
            "Extracting ./t10k-images-idx3-ubyte.gz\n",
            "Extracting ./t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0HxSxjr6BYPB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "################################\n",
        "#FIRST DEEP ANN\n",
        "################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fy-GkvfwU7_7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 20\n",
        "batch_size = 128  # Decrease batch size if you don't have enough memory\n",
        "display_step = 1\n",
        "\n",
        "n_input = 784  # MNIST data input (img shape: 28*28)\n",
        "n_classes = 10  # MNIST total classes (0-9 digits)\n",
        "\n",
        "n_hidden_layer = 256 # layer number of features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FIVvXr8nU9e2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Store layers weight & bias\n",
        "weights = {\n",
        "    'hidden_layer': tf.Variable(tf.random_normal([n_input, n_hidden_layer])),\n",
        "    'out': tf.Variable(tf.random_normal([n_hidden_layer, n_classes]))\n",
        "}\n",
        "biases = {\n",
        "    'hidden_layer': tf.Variable(tf.random_normal([n_hidden_layer])),\n",
        "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JLPt6dpyVxna",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tf Graph input\n",
        "x = tf.placeholder(\"float\", [None, 28, 28, 1])\n",
        "y = tf.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "x_flat = tf.reshape(x, [-1, n_input])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "myD-Tag1XnzI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hidden layer with RELU activation\n",
        "layer_1 = tf.add(tf.matmul(x_flat, weights['hidden_layer']),\\\n",
        "    biases['hidden_layer'])\n",
        "layer_1 = tf.nn.relu(layer_1)\n",
        "# Output layer with linear activation\n",
        "logits = tf.add(tf.matmul(layer_1, weights['out']), biases['out'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rSG0os8OXsf7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define loss and optimizer\n",
        "cost = tf.reduce_mean(\\\n",
        "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
        "    .minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dGMu2dYSXudL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initializing the variables\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "\n",
        "# Launch the graph\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    # Training cycle\n",
        "    for epoch in range(training_epochs):\n",
        "        total_batch = int(mnist.train.num_examples/batch_size)\n",
        "        # Loop over all batches\n",
        "        for i in range(total_batch):\n",
        "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "            # Run optimization op (backprop) and cost op (to get loss value)\n",
        "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "15carcvAXwbr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "################################\n",
        "#FIRST DEEP ANN -- ENDS\n",
        "################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "va6TShUCC5wB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "################################\n",
        "#saving a model-ex\n",
        "################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u68K5BWNd4vj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#SAVING VARIABLES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cO-BKLHzC5vA",
        "colab_type": "code",
        "outputId": "470b5887-7943-45b6-c1e3-b5f290ddde47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# The file path to save the data\n",
        "save_file = './model.ckpt'\n",
        "\n",
        "# Two Tensor Variables: weights and bias\n",
        "weights = tf.Variable(tf.truncated_normal([2, 3]))\n",
        "bias = tf.Variable(tf.truncated_normal([3]))\n",
        "\n",
        "# Class used to save and/or restore Tensor Variables\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    # Initialize all the Variables\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    # Show the values of weights and bias\n",
        "    print('Weights:')\n",
        "    print(sess.run(weights))\n",
        "    print('Bias:')\n",
        "    print(sess.run(bias))\n",
        "\n",
        "    # Save the model\n",
        "    saver.save(sess, save_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights:\n",
            "[[-0.6447532   0.9678028   0.18237594]\n",
            " [ 0.9869114   0.18971403 -1.2686735 ]]\n",
            "Bias:\n",
            "[-0.87420017 -0.52040946 -0.15281747]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pnE1QmFrNuKG",
        "colab_type": "code",
        "outputId": "e3f988a4-6f26-4b73-e4d1-adf35587cefd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "# Remove the previous weights and bias\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Two Variables: weights and bias\n",
        "weights = tf.Variable(tf.truncated_normal([2, 3]))\n",
        "bias = tf.Variable(tf.truncated_normal([3]))\n",
        "\n",
        "# Class used to save and/or restore Tensor Variables\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    # Load the weights and bias\n",
        "    saver.restore(sess, save_file)\n",
        "\n",
        "    # Show the values of weights and bias\n",
        "    print('Weight:')\n",
        "    print(sess.run(weights))\n",
        "    print('Bias:')\n",
        "    print(sess.run(bias))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./model.ckpt\n",
            "Weight:\n",
            "[[ 0.316214   -0.34304318  1.453102  ]\n",
            " [-0.06462945  0.5385332   0.4608421 ]]\n",
            "Bias:\n",
            "[1.4897364  0.8140362  0.31767517]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KcikFFQud1op",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Save a Trained Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "veYCWYbheK3q",
        "colab_type": "code",
        "outputId": "54c5c58a-9f4a-4793-9cf3-3afb837a01d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# Remove previous Tensors and Operations\n",
        "tf.reset_default_graph()\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import numpy as np\n",
        "\n",
        "learning_rate = 0.001\n",
        "n_input = 784  # MNIST data input (img shape: 28*28)\n",
        "n_classes = 10  # MNIST total classes (0-9 digits)\n",
        "\n",
        "# Import MNIST data\n",
        "mnist = input_data.read_data_sets('.', one_hot=True)\n",
        "\n",
        "# Features and Labels\n",
        "features = tf.placeholder(tf.float32, [None, n_input])\n",
        "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
        "\n",
        "# Weights & bias\n",
        "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
        "bias = tf.Variable(tf.random_normal([n_classes]))\n",
        "\n",
        "# Logits - xW + b\n",
        "logits = tf.add(tf.matmul(features, weights), bias)\n",
        "\n",
        "# Define loss and optimizer\n",
        "cost = tf.reduce_mean(\\\n",
        "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
        "    .minimize(cost)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./train-images-idx3-ubyte.gz\n",
            "Extracting ./train-labels-idx1-ubyte.gz\n",
            "Extracting ./t10k-images-idx3-ubyte.gz\n",
            "Extracting ./t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NOS2xZpPeQoh",
        "colab_type": "code",
        "outputId": "551700b7-81b2-41e8-df54-8a7530c00385",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "save_file = './train_model.ckpt'\n",
        "batch_size = 128\n",
        "n_epochs = 100\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "# Launch the graph\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    # Training cycle\n",
        "    for epoch in range(n_epochs):\n",
        "        total_batch = math.ceil(mnist.train.num_examples / batch_size)\n",
        "\n",
        "        # Loop over all batches\n",
        "        for i in range(total_batch):\n",
        "            batch_features, batch_labels = mnist.train.next_batch(batch_size)\n",
        "            sess.run(\n",
        "                optimizer,\n",
        "                feed_dict={features: batch_features, labels: batch_labels})\n",
        "\n",
        "        # Print status for every 10 epochs\n",
        "        if epoch % 10 == 0:\n",
        "            valid_accuracy = sess.run(\n",
        "                accuracy,\n",
        "                feed_dict={\n",
        "                    features: mnist.validation.images,\n",
        "                    labels: mnist.validation.labels})\n",
        "            print('Epoch {:<3} - Validation Accuracy: {}'.format(\n",
        "                epoch,\n",
        "                valid_accuracy))\n",
        "\n",
        "    # Save the model\n",
        "    saver.save(sess, save_file)\n",
        "    print('Trained Model Saved.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0   - Validation Accuracy: 0.14980000257492065\n",
            "Epoch 10  - Validation Accuracy: 0.321399986743927\n",
            "Epoch 20  - Validation Accuracy: 0.4408000111579895\n",
            "Epoch 30  - Validation Accuracy: 0.5212000012397766\n",
            "Epoch 40  - Validation Accuracy: 0.579800009727478\n",
            "Epoch 50  - Validation Accuracy: 0.6263999938964844\n",
            "Epoch 60  - Validation Accuracy: 0.6567999720573425\n",
            "Epoch 70  - Validation Accuracy: 0.6794000267982483\n",
            "Epoch 80  - Validation Accuracy: 0.699999988079071\n",
            "Epoch 90  - Validation Accuracy: 0.7193999886512756\n",
            "Trained Model Saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y9xhv3eReTY8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Load Trained Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UgoiuthmeVM2",
        "colab_type": "code",
        "outputId": "7f54a520-2328-4b13-b916-9c33b5858fa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "saver = tf.train.Saver()\n",
        "\n",
        "# Launch the graph\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, save_file)\n",
        "\n",
        "    test_accuracy = sess.run(\n",
        "        accuracy,\n",
        "        feed_dict={features: mnist.test.images, labels: mnist.test.labels})\n",
        "\n",
        "print('Test Accuracy: {}'.format(test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./train_model.ckpt\n",
            "Test Accuracy: 0.7293000221252441\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bVQfVohbiatS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#FINETUNING --ERROR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8b4wNCg2J_Zz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f8tBQP9_ibBn",
        "colab_type": "code",
        "outputId": "b4048607-06ed-49d1-bf0e-e73ce1f21017",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3855
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Remove the previous weights and bias\n",
        "tf.reset_default_graph()\n",
        "\n",
        "save_file = 'model.ckpt'\n",
        "\n",
        "# Two Tensor Variables: weights and bias\n",
        "weights = tf.Variable(tf.truncated_normal([2, 3]))\n",
        "bias = tf.Variable(tf.truncated_normal([3]))\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "# Print the name of Weights and Bias\n",
        "print('Save Weights: {}'.format(weights.name))\n",
        "print('Save Bias: {}'.format(bias.name))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    saver.save(sess, save_file)\n",
        "\n",
        "# Remove the previous weights and bias\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Two Variables: weights and bias\n",
        "bias = tf.Variable(tf.truncated_normal([3]))\n",
        "weights = tf.Variable(tf.truncated_normal([2, 3]))\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "# Print the name of Weights and Bias\n",
        "print('Load Weights: {}'.format(weights.name))\n",
        "print('Load Bias: {}'.format(bias.name))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    # Load the weights and bias - ERROR\n",
        "    saver.restore(sess, save_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Save Weights: Variable:0\n",
            "Save Bias: Variable_1:0\n",
            "Load Weights: Variable_1:0\n",
            "Load Bias: Variable:0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [2,3] rhs shape= [3]\n\t [[{{node save/Assign_1}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1275\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1276\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1277\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [2,3] rhs shape= [3]\n\t [[node save/Assign_1 (defined at <ipython-input-1-32cce566247b>:29) ]]\n\nCaused by op 'save/Assign_1', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-32cce566247b>\", line 29, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 844, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 881, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 354, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/saveable_object_util.py\", line 73, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/state_ops.py\", line 223, in assign\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 64, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [2,3] rhs shape= [3]\n\t [[node save/Assign_1 (defined at <ipython-input-1-32cce566247b>:29) ]]\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-32cce566247b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Load the weights and bias - ERROR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0;31m# We add a more reasonable error message here to help users (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1312\u001b[0;31m           err, \"a mismatch between the current graph and the graph\")\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [2,3] rhs shape= [3]\n\t [[node save/Assign_1 (defined at <ipython-input-1-32cce566247b>:29) ]]\n\nCaused by op 'save/Assign_1', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-32cce566247b>\", line 29, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 844, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 881, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 354, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/saveable_object_util.py\", line 73, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/state_ops.py\", line 223, in assign\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 64, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [2,3] rhs shape= [3]\n\t [[node save/Assign_1 (defined at <ipython-input-1-32cce566247b>:29) ]]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ZqeHvwZnTwTw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EG8W_YVcKApJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##SET NAME MANUALLY"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2LkSdbi1KA9A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "save_file = 'model.ckpt'\n",
        "\n",
        "# Two Tensor Variables: weights and bias\n",
        "weights = tf.Variable(tf.truncated_normal([2, 3]), name='weights_0')\n",
        "bias = tf.Variable(tf.truncated_normal([3]), name='bias_0')\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "# Print the name of Weights and Bias\n",
        "print('Save Weights: {}'.format(weights.name))\n",
        "print('Save Bias: {}'.format(bias.name))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    saver.save(sess, save_file)\n",
        "\n",
        "# Remove the previous weights and bias\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Two Variables: weights and bias\n",
        "bias = tf.Variable(tf.truncated_normal([3]), name='bias_0')\n",
        "weights = tf.Variable(tf.truncated_normal([2, 3]) ,name='weights_0')\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "# Print the name of Weights and Bias\n",
        "print('Load Weights: {}'.format(weights.name))\n",
        "print('Load Bias: {}'.format(bias.name))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    # Load the weights and bias - No Error\n",
        "    saver.restore(sess, save_file)\n",
        "\n",
        "print('Loaded Weights and Bias successfully.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jGzsXwGRTxzv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xsi5u5ivTyE_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "keep_prob = tf.placeholder(tf.float32) # probability to keep units\n",
        "\n",
        "hidden_layer = tf.add(tf.matmul(features, weights[0]), biases[0])\n",
        "hidden_layer = tf.nn.relu(hidden_layer)\n",
        "hidden_layer = tf.nn.dropout(hidden_layer, keep_prob)\n",
        "\n",
        "logits = tf.add(tf.matmul(hidden_layer, weights[1]), biases[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xM5lEKFvUOiN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##MODEL WITH DROPOUT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "00V0KEfuUQVW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Quiz Solution\n",
        "# Note: You can't run code in this tab\n",
        "import tensorflow as tf\n",
        "\n",
        "hidden_layer_weights = [\n",
        "    [0.1, 0.2, 0.4],\n",
        "    [0.4, 0.6, 0.6],\n",
        "    [0.5, 0.9, 0.1],\n",
        "    [0.8, 0.2, 0.8]]\n",
        "out_weights = [\n",
        "    [0.1, 0.6],\n",
        "    [0.2, 0.1],\n",
        "    [0.7, 0.9]]\n",
        "\n",
        "# set random seed\n",
        "tf.set_random_seed(123456)\n",
        "\n",
        "# Weights and biases\n",
        "weights = [\n",
        "    tf.Variable(hidden_layer_weights),\n",
        "    tf.Variable(out_weights)]\n",
        "biases = [\n",
        "    tf.Variable(tf.zeros(3)),\n",
        "    tf.Variable(tf.zeros(2))]\n",
        "\n",
        "# Input\n",
        "features = tf.Variable([[0.0, 2.0, 3.0, 4.0], [0.1, 0.2, 0.3, 0.4], [11.0, 12.0, 13.0, 14.0]])\n",
        "\n",
        "# TODO: Create Model with Dropout\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "hidden_layer = tf.add(tf.matmul(features, weights[0]), biases[0])\n",
        "hidden_layer = tf.nn.relu(hidden_layer)\n",
        "hidden_layer = tf.nn.dropout(hidden_layer, keep_prob)\n",
        "\n",
        "logits = tf.add(tf.matmul(hidden_layer, weights[1]), biases[1])\n",
        "\n",
        "# TODO: save and print session results as variable named \"output\"\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    output = sess.run(logits, feed_dict={keep_prob: 0.5})\n",
        "    print(output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BjVYUQ8AAmYs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###Convolutional Output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hvquMVljAmyv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
        "filter_weights = tf.Variable(tf.truncated_normal((8, 8, 3, 20))) # (height, width, input_depth, output_depth)\n",
        "filter_bias = tf.Variable(tf.zeros(20))\n",
        "strides = [1, 2, 2, 1] # (batch, height, width, depth)\n",
        "padding = 'SAME'\n",
        "conv = tf.nn.conv2d(input, filter_weights, strides, padding) + filter_bias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8TDR3auXkHpP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###CONVNET # 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X0CLbqNAkKiA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Output depth\n",
        "k_output = 64\n",
        "\n",
        "# Image Properties\n",
        "image_width = 10\n",
        "image_height = 10\n",
        "color_channels = 3\n",
        "\n",
        "# Convolution filter\n",
        "filter_size_width = 5\n",
        "filter_size_height = 5\n",
        "\n",
        "# Input/Image\n",
        "input = tf.placeholder(\n",
        "    tf.float32,\n",
        "    shape=[None, image_height, image_width, color_channels])\n",
        "\n",
        "# Weight and bias\n",
        "weight = tf.Variable(tf.truncated_normal(\n",
        "    [filter_size_height, filter_size_width, color_channels, k_output]))\n",
        "bias = tf.Variable(tf.zeros(k_output))\n",
        "\n",
        "# Apply Convolution\n",
        "conv_layer = tf.nn.conv2d(input, weight, strides=[1, 2, 2, 1], padding='SAME')\n",
        "# Add bias\n",
        "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
        "# Apply activation function\n",
        "conv_layer = tf.nn.relu(conv_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tZ97JtZDo4fq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##max pooling"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TydrjZLFo6EB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "...\n",
        "conv_layer = tf.nn.conv2d(input, weight, strides=[1, 2, 2, 1], padding='SAME')\n",
        "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
        "conv_layer = tf.nn.relu(conv_layer)\n",
        "# Apply Max Pooling\n",
        "conv_layer = tf.nn.max_pool(\n",
        "    conv_layer,\n",
        "    ksize=[1, 2, 2, 1],\n",
        "    strides=[1, 2, 2, 1],\n",
        "    padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Rf0upTQrW_O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###Mx Pooling Ex"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o05QWNrZrYgh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input = tf.placeholder(tf.float32, (None, 4, 4, 5))\n",
        "filter_shape = [1, 2, 2, 1]\n",
        "strides = [1, 2, 2, 1]\n",
        "padding = 'VALID'\n",
        "pool = tf.nn.max_pool(input, filter_shape, strides, padding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "02GkeDc1oCXB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###### CONVNET ---COMPLETE MODEL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HsnBxc38oII9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6ad6ebe5-1845-4860-9701-0b5d5d5641b8"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.00001\n",
        "epochs = 10\n",
        "batch_size = 128\n",
        "\n",
        "# Number of samples to calculate validation and accuracy\n",
        "# Decrease this if you're running out of memory to calculate accuracy\n",
        "test_valid_size = 256\n",
        "\n",
        "# Network Parameters\n",
        "n_classes = 10  # MNIST total classes (0-9 digits)\n",
        "dropout = 0.75  # Dropout, probability to keep units"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./train-images-idx3-ubyte.gz\n",
            "Extracting ./train-labels-idx1-ubyte.gz\n",
            "Extracting ./t10k-images-idx3-ubyte.gz\n",
            "Extracting ./t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QhST1-0NoTi_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Store layers weight & bias\n",
        "weights = {\n",
        "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
        "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
        "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
        "    'out': tf.Variable(tf.random_normal([1024, n_classes]))}\n",
        "\n",
        "biases = {\n",
        "    'bc1': tf.Variable(tf.random_normal([32])),\n",
        "    'bc2': tf.Variable(tf.random_normal([64])),\n",
        "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
        "    'out': tf.Variable(tf.random_normal([n_classes]))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HJiQZlCIqt3K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv2d(x, W, b, strides=1):\n",
        "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
        "    x = tf.nn.bias_add(x, b)\n",
        "    return tf.nn.relu(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PeyOfFB7rux9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##In TensorFlow, strides is an array of 4 elements; the first element in this array indicates the stride for batch and last element indicates stride for features. It's good practice to remove the batches or features you want to skip from the data set rather than use a stride to skip them. You can always set the first and last element to 1 in strides in order to use all batches and features."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uVKg9WRhsBOp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def maxpool2d(x, k=2):\n",
        "    return tf.nn.max_pool(\n",
        "        x,\n",
        "        ksize=[1, k, k, 1],\n",
        "        strides=[1, k, k, 1],\n",
        "        padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QpTajvGb8oG0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv_net(x, weights, biases, dropout):\n",
        "    # Layer 1 - 28*28*1 to 14*14*32\n",
        "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
        "    conv1 = maxpool2d(conv1, k=2)\n",
        "\n",
        "    # Layer 2 - 14*14*32 to 7*7*64\n",
        "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
        "    conv2 = maxpool2d(conv2, k=2)\n",
        "\n",
        "    # Fully connected layer - 7*7*64 to 1024\n",
        "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
        "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
        "    fc1 = tf.nn.relu(fc1)\n",
        "    fc1 = tf.nn.dropout(fc1, dropout)\n",
        "\n",
        "    # Output Layer - class prediction - 1024 to 10\n",
        "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qo7ENo_48wiG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tf Graph input\n",
        "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
        "y = tf.placeholder(tf.float32, [None, n_classes])\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "# Model\n",
        "logits = conv_net(x, weights, biases, keep_prob)\n",
        "\n",
        "# Define loss and optimizer\n",
        "cost = tf.reduce_mean(\\\n",
        "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
        "    .minimize(cost)\n",
        "\n",
        "# Accuracy\n",
        "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Initializing the variables\n",
        "init = tf. global_variables_initializer()\n",
        "\n",
        "# Launch the graph\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for batch in range(mnist.train.num_examples//batch_size):\n",
        "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "            sess.run(optimizer, feed_dict={\n",
        "                x: batch_x,\n",
        "                y: batch_y,\n",
        "                keep_prob: dropout})\n",
        "\n",
        "            # Calculate batch loss and accuracy\n",
        "            loss = sess.run(cost, feed_dict={\n",
        "                x: batch_x,\n",
        "                y: batch_y,\n",
        "                keep_prob: 1.})\n",
        "            valid_acc = sess.run(accuracy, feed_dict={\n",
        "                x: mnist.validation.images[:test_valid_size],\n",
        "                y: mnist.validation.labels[:test_valid_size],\n",
        "                keep_prob: 1.})\n",
        "\n",
        "            print('Epoch {:>2}, Batch {:>3} -'\n",
        "                  'Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
        "                epoch + 1,\n",
        "                batch + 1,\n",
        "                loss,\n",
        "                valid_acc))\n",
        "\n",
        "    # Calculate Test Accuracy\n",
        "    test_acc = sess.run(accuracy, feed_dict={\n",
        "        x: mnist.test.images[:test_valid_size],\n",
        "        y: mnist.test.labels[:test_valid_size],\n",
        "        keep_prob: 1.})\n",
        "    print('Testing Accuracy: {}'.format(test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XQDdSHmzDo6_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Setup the strides, padding and filter weight/bias such that\n",
        "the output shape is (1, 2, 2, 3).\n",
        "\"\"\"\n",
        "# `tf.nn.conv2d` requires the input be 4D (batch_size, height, width, depth)\n",
        "# (1, 4, 4, 1)\n",
        "x = np.array([\n",
        "    [0, 1, 0.5, 10],\n",
        "    [2, 2.5, 1, -8],\n",
        "    [4, 0, 5, 6],\n",
        "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
        "X = tf.constant(x)\n",
        "\n",
        "def conv2d(input_array):\n",
        "  weights = {\n",
        "      'wc1': tf.Variable(tf.random_normal([1, 5, 1, 3]))}\n",
        "\n",
        "  biases = {\n",
        "      'bc1': tf.Variable(tf.random_normal([3]))}\n",
        "\n",
        "    # Filter (weights and bias)\n",
        "    # The shape of the filter weight is (height, width, input_depth, output_depth)\n",
        "    # The shape of the filter bias is (output_depth,)\n",
        "    # TODO: Define the filter weights `F_W` and filter bias `F_b`.\n",
        "    # NOTE: Remember to wrap them in `tf.Variable`, they are trainable parameters after all.\n",
        "    F_W = tf.Variable(tf.random_normal([5, 5, 1, 32])\n",
        "    F_b = tf.Variable(tf.random_normal([3]))\n",
        "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
        "    strides = [, , , ]\n",
        "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
        "    padding = 'SAME'\n",
        "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#conv2d\n",
        "    # `tf.nn.conv2d` does not include the bias computation so we have to add it ourselves after.\n",
        "    return tf.nn.conv2d(input_array, F_W, strides, padding) + F_b\n",
        "\n",
        "output = conv2d(X)\n",
        "output"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}